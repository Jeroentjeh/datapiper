% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bayesian_optimisation.R
\name{find_model_through_bayes}
\alias{find_model_through_bayes}
\title{Hyper parameter search using bayesian optimisation}
\usage{
find_model_through_bayes(train, test, response,
  preprocess_pipes = list(function(train, test) return(list(train = train,
  test = train, .predict = function(data) return(data)))), models, metrics,
  target_metric, higher_is_better, N_init = 20, N_experiment = 40,
  sigma_noise = 1e-08, prepend_data_checker = T,
  on_missing_column = c("error", "add")[1], on_extra_column = c("remove",
  "error")[1], on_type_error = c("ignore", "error")[1], seed = 1,
  verbose = T, save_model = F)
}
\arguments{
\item{train}{The training dataset}

\item{test}{The testing dataset}

\item{response}{The response column as a string}

\item{preprocess_pipes}{List of preprocessing pipelines generated using \code{\link{pipeline}}.}

\item{models}{A list of models. Each model should be a list, containing at least a training function \code{.train} and a \code{.predict} function, plus named
vectors of parameters to explore.

The \code{.train} function has to take a \code{data} argument that stores the training data and a \code{...} argument for the parameters.
The \code{.predict} function needs to take two arguments, where the first is the model and the second the new dataset.

If a parameter only takes a single value, you can use a vector to store options. Otherwise use a list.

You can use \code{\link{model_trainer}} as a wrapper for this list. It will also test your inputs.}

\item{metrics}{A list of metrics (functions) that need to be calculated on the train and test response and predictions. Must be named.}

\item{target_metric}{The name of the metric to optimise. Optimisation will be done on the testset performance of this metric.}

\item{higher_is_better}{A flag indicating if a high value of \code{target_metric} indicates a good result.}

\item{N_init}{Number of iterations to initialise the bayesian optimisation with.}

\item{N_experiment}{Number of experimentations done with the bayesian optimisation.
\itemize{
\item A numeric vector with as many entries as \code{x}.
\item A numeric matrix with as many columns as entries in \code{x}.
}}

\item{sigma_noise}{An estimate of the inherent noise in sampling from. If this is set below 1e-8, we will not reconsider previously
tried configurations.}

\item{prepend_data_checker}{Flag indicating if \code{\link{pipe_check}} should be prepended before all pipelines.}

\item{on_missing_column}{See \code{\link{pipe_check}} for details.}

\item{on_extra_column}{See \code{\link{pipe_check}} for details.}

\item{on_type_error}{See \code{\link{pipe_check}} for details.}

\item{seed}{Random seed to set each time before a model is trained. Set this to 0 to ignore setting seeds.}

\item{verbose}{Should intermediate updates be printed.}

\item{save_model}{Flag indicating if the generated models should be saved. Defaults to False.}
}
\value{
A dataframe containing the training function, a list of parameters used to train the function, and one column for each metric / dataset combination.
}
\description{
Hyper parameter search using bayesian optimisation
}
\details{
This implementation is still in an early phase. Bugs may exist, but results so far have been promising (Dec 2018).
}
